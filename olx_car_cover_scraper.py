# -*- coding: utf-8 -*-
"""olx_car_cover_scraper

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X1ZSB5KRUHoZs8Vt423sHjzhqdT7IVto
"""

import requests
from bs4 import BeautifulSoup

def fetch_olx_results(query="car-cover", page_limit=1):
    base_url = "https://www.olx.in/items/q-"
    results = []

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }

    for page in range(1, page_limit + 1):
        url = f"{base_url}{query}?page={page}"
        print(f"Fetching: {url}")
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            print(f"Failed to fetch page {page}")
            continue

        soup = BeautifulSoup(response.text, "html.parser")
        listings = soup.find_all("li", class_="EIR5N")  # OLX listing class

        for item in listings:
            title_tag = item.find("span", {"data-aut-id": "itemTitle"})
            price_tag = item.find("span", {"data-aut-id": "itemPrice"})
            location_tag = item.find("span", {"data-aut-id": "item-location"})

            title = title_tag.get_text(strip=True) if title_tag else "N/A"
            price = price_tag.get_text(strip=True) if price_tag else "N/A"
            location = location_tag.get_text(strip=True) if location_tag else "N/A"

            results.append({
                "title": title,
                "price": price,
                "location": location
            })

    return results

def save_results(results, filename="olx_car_covers.txt"):
    with open(filename, "w", encoding="utf-8") as file:
        for i, item in enumerate(results, 1):
            file.write(f"{i}. {item['title']} - {item['price']} - {item['location']}\n")
    print(f"Saved {len(results)} results to {filename}")

if __name__ == "__main__":
    listings = fetch_olx_results(query="car-cover", page_limit=2)  # You can change page_limit
    save_results(listings)